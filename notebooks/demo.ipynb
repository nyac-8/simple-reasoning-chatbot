{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Reasoning Chatbot Demo\n",
    "\n",
    "This notebook demonstrates the v1 reasoning chatbot with visible thinking steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# Add parent directory to path\n",
    "notebook_dir = Path.cwd()\n",
    "parent_dir = notebook_dir.parent if notebook_dir.name == 'notebooks' else notebook_dir\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Import modules\n",
    "from src.graph import create_graph\n",
    "from src.state import State\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class for managing sessions with colored output\n",
    "class ReasoningChatbot:\n",
    "    def __init__(self):\n",
    "        self.workflow = create_graph()\n",
    "        self.session_id = str(uuid.uuid4())\n",
    "        self.history: List[Tuple[str, str]] = []\n",
    "        \n",
    "    def ask(self, question: str, show_reasoning: bool = True, stream_reasoning: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Ask a question and get a reasoned response with colored output\n",
    "        \n",
    "        Args:\n",
    "            question: The question to ask\n",
    "            show_reasoning: Whether to show reasoning steps at the end\n",
    "            stream_reasoning: Whether to show reasoning steps in real-time as they happen\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create thread ID\n",
    "        thread_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Convert history to messages\n",
    "        messages = []\n",
    "        for q, a in self.history:\n",
    "            messages.append(HumanMessage(content=q))\n",
    "            messages.append(AIMessage(content=a))\n",
    "        \n",
    "        # Initialize state\n",
    "        initial_state: State = {\n",
    "            \"session_id\": self.session_id,\n",
    "            \"thread_id\": thread_id,\n",
    "            \"messages\": messages,\n",
    "            \"history\": self.history,\n",
    "            \"current_question\": question,\n",
    "            \"reasoning_steps\": [],\n",
    "            \"reasoning_count\": 0,\n",
    "            \"ready_to_answer\": False,\n",
    "            \"context\": {},\n",
    "            \"tools\": [],\n",
    "            \"final_answer\": None\n",
    "        }\n",
    "        \n",
    "        # Display question\n",
    "        display(Markdown(f\"## Question\\n{question}\"))\n",
    "        display(HTML(\"<hr style='border: 1px solid #ddd;'>\"))\n",
    "        \n",
    "        if stream_reasoning:\n",
    "            display(Markdown(\"### Reasoning Process\"))\n",
    "            \n",
    "            # Stream the workflow to show reasoning in real-time\n",
    "            for chunk in self.workflow.stream(initial_state):\n",
    "                if 'orchestrator' in chunk:\n",
    "                    # New reasoning step was added\n",
    "                    updates = chunk['orchestrator']\n",
    "                    if 'reasoning_steps' in updates and updates['reasoning_steps']:\n",
    "                        step_num = updates.get('reasoning_count', len(updates['reasoning_steps']))\n",
    "                        latest_step = updates['reasoning_steps'][-1]\n",
    "                        \n",
    "                        # Display reasoning in yellow/amber color\n",
    "                        reasoning_html = f\"\"\"\n",
    "                        <div style='background-color: #fff9e6; border-left: 4px solid #ffc107; padding: 10px; margin: 10px 0;'>\n",
    "                            <strong style='color: #ff9800;'>Step {step_num}:</strong>\n",
    "                            <pre style='color: #d68000; white-space: pre-wrap; font-family: monospace;'>{latest_step.content}</pre>\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "                        display(HTML(reasoning_html))\n",
    "                        \n",
    "                        if updates.get('ready_to_answer'):\n",
    "                            display(Markdown(\"**Reasoning complete, generating answer...**\"))\n",
    "                        else:\n",
    "                            display(Markdown(\"*Continuing to reason...*\"))\n",
    "                elif 'writer' in chunk:\n",
    "                    # Final answer is being generated\n",
    "                    updates = chunk['writer']\n",
    "                    if 'final_answer' in updates:\n",
    "                        final_state = updates\n",
    "            \n",
    "            # Get the final state\n",
    "            if 'final_answer' not in locals():\n",
    "                final_state = initial_state\n",
    "                for chunk in self.workflow.stream(initial_state):\n",
    "                    final_state.update(chunk.get('writer', chunk.get('orchestrator', {})))\n",
    "        else:\n",
    "            # Run the workflow\n",
    "            final_state = self.workflow.invoke(initial_state)\n",
    "            \n",
    "            # Display reasoning steps if requested\n",
    "            if show_reasoning and final_state.get(\"reasoning_steps\"):\n",
    "                display(Markdown(\"### Reasoning Steps\"))\n",
    "                for i, step in enumerate(final_state[\"reasoning_steps\"], 1):\n",
    "                    # Display reasoning in yellow/amber color\n",
    "                    reasoning_html = f\"\"\"\n",
    "                    <div style='background-color: #fff9e6; border-left: 4px solid #ffc107; padding: 10px; margin: 10px 0;'>\n",
    "                        <strong style='color: #ff9800;'>Step {i}:</strong>\n",
    "                        <pre style='color: #d68000; white-space: pre-wrap; font-family: monospace;'>{step.content if len(step.content) <= 500 else step.content[:500] + '...'}</pre>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                    display(HTML(reasoning_html))\n",
    "        \n",
    "        # Get final answer\n",
    "        final_answer = final_state.get(\"final_answer\", \"No answer generated\")\n",
    "        \n",
    "        # Update history\n",
    "        self.history = final_state.get(\"history\", self.history)\n",
    "        \n",
    "        # Display final answer in green\n",
    "        display(HTML(\"<hr style='border: 1px solid #ddd; margin: 20px 0;'>\"))\n",
    "        answer_html = f\"\"\"\n",
    "        <div style='background-color: #e8f5e9; border-left: 4px solid #4caf50; padding: 15px; margin: 10px 0;'>\n",
    "            <h3 style='color: #2e7d32; margin-top: 0;'>Final Answer</h3>\n",
    "            <div style='color: #1b5e20; white-space: pre-wrap; font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif;'>{final_answer}</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(answer_html))\n",
    "        \n",
    "        return final_answer\n",
    "    \n",
    "    def reset_session(self):\n",
    "        \"\"\"Start a new session\"\"\"\n",
    "        self.session_id = str(uuid.uuid4())\n",
    "        self.history = []\n",
    "        display(Markdown(\"**Session reset**\"))\n",
    "\n",
    "# Create chatbot instance\n",
    "chatbot = ReasoningChatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example 1: Simple Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple question - should require minimal reasoning\n",
    "answer = chatbot.ask(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example 2: Complex Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Complex question - should trigger more reasoning steps\n",
    "answer = chatbot.ask(\"Explain the Black-Scholes model in simple terms, and why is it important in finance?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example 3: Follow-up Question (Uses History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question that uses conversation context\n",
    "answer = chatbot.ask(\"What are its main limitations?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example 4: Math Problem with Streaming Reasoning\n",
    "\n",
    "Watch the reasoning unfold in real-time for a math problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math problem with real-time reasoning display\n",
    "# This shows each reasoning step as it happens, not waiting until the end\n",
    "\n",
    "answer = chatbot.ask(\n",
    "    \"A train travels from City A to City B at 60 mph. The return trip at 40 mph takes 2 hours longer. What's the distance between the cities?\",\n",
    "    stream_reasoning=True  # This enables real-time display\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same functionality but without showing reasoning\n",
    "answer = chatbot.ask(\n",
    "    \"What's the difference between machine learning and deep learning?\",\n",
    "    show_reasoning=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chatbot.ask(\n",
    "    \"Sumarize our converation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread Lifecycle Viewer\n",
    "\n",
    "View all messages and state changes in a thread's lifecycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def view_thread_lifecycle(question: str):\n",
    "    \"\"\"\n",
    "    Execute a question and display the complete thread lifecycle with colored output\n",
    "    \"\"\"\n",
    "    display(HTML(\"\"\"\n",
    "    <div style='background-color: #f5f5f5; padding: 20px; border-radius: 8px;'>\n",
    "        <h2 style='color: #333; margin-top: 0;'>THREAD LIFECYCLE VIEWER</h2>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    display(Markdown(f\"### Question\\n{question}\"))\n",
    "    \n",
    "    thread_id = str(uuid.uuid4())\n",
    "    display(Markdown(f\"**Thread ID:** `{thread_id}`\\n\\n**Session ID:** `{chatbot.session_id}`\"))\n",
    "    \n",
    "    # Initial state\n",
    "    initial_state: State = {\n",
    "        \"session_id\": chatbot.session_id,\n",
    "        \"thread_id\": thread_id,\n",
    "        \"messages\": [],\n",
    "        \"history\": chatbot.history,\n",
    "        \"current_question\": question,\n",
    "        \"reasoning_steps\": [],\n",
    "        \"reasoning_count\": 0,\n",
    "        \"ready_to_answer\": False,\n",
    "        \"context\": {},\n",
    "        \"tools\": [],\n",
    "        \"final_answer\": None\n",
    "    }\n",
    "    \n",
    "    display(Markdown(\"### Initial State\"))\n",
    "    state_info = []\n",
    "    for key, value in initial_state.items():\n",
    "        if key not in ['messages', 'history']:\n",
    "            state_info.append(f\"- **{key}**: {value}\")\n",
    "    display(Markdown(\"\\n\".join(state_info)))\n",
    "    \n",
    "    # Track all state changes\n",
    "    state_changes = []\n",
    "    message_log = []\n",
    "    \n",
    "    display(HTML(\"<hr style='margin: 20px 0;'>\"))\n",
    "    display(Markdown(\"### Execution Flow\"))\n",
    "    \n",
    "    # Stream the workflow to capture all transitions\n",
    "    for i, chunk in enumerate(chatbot.workflow.stream(initial_state), 1):\n",
    "        node_name = list(chunk.keys())[0]\n",
    "        updates = chunk[node_name]\n",
    "        \n",
    "        node_html = f\"\"\"\n",
    "        <div style='background-color: #e3f2fd; border-left: 4px solid #2196f3; padding: 10px; margin: 10px 0;'>\n",
    "            <strong style='color: #1565c0;'>Step {i}: {node_name.upper()} NODE</strong>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Log state changes\n",
    "        if updates:\n",
    "            state_html = \"<ul style='color: #424242; margin: 5px 0;'>\"\n",
    "            for key, value in updates.items():\n",
    "                if key == 'reasoning_steps' and value:\n",
    "                    state_html += f\"<li><strong>{key}:</strong> Added step {len(value)}</li>\"\n",
    "                    # Store reasoning content\n",
    "                    for step in value:\n",
    "                        if hasattr(step, 'content'):\n",
    "                            message_log.append(('reasoning', step.content))\n",
    "                elif key == 'messages' and value:\n",
    "                    state_html += f\"<li><strong>{key}:</strong> {len(value)} messages</li>\"\n",
    "                elif key == 'final_answer':\n",
    "                    state_html += f\"<li><strong>{key}:</strong> Generated ({len(str(value))} chars)</li>\"\n",
    "                    message_log.append(('answer', value))\n",
    "                else:\n",
    "                    state_html += f\"<li><strong>{key}:</strong> {value}</li>\"\n",
    "            state_html += \"</ul>\"\n",
    "            node_html += state_html\n",
    "            \n",
    "            state_changes.append({\n",
    "                'node': node_name,\n",
    "                'updates': updates\n",
    "            })\n",
    "        \n",
    "        node_html += \"</div>\"\n",
    "        display(HTML(node_html))\n",
    "    \n",
    "    display(HTML(\"<hr style='margin: 20px 0;'>\"))\n",
    "    display(Markdown(\"### All Messages Generated\"))\n",
    "    \n",
    "    for msg_type, content in message_log:\n",
    "        if msg_type == 'reasoning':\n",
    "            # Yellow/amber for reasoning\n",
    "            reasoning_html = f\"\"\"\n",
    "            <div style='background-color: #fff9e6; border-left: 4px solid #ffc107; padding: 10px; margin: 10px 0;'>\n",
    "                <strong style='color: #ff9800;'>Reasoning Step:</strong>\n",
    "                <pre style='color: #d68000; white-space: pre-wrap; font-family: monospace;'>{content[:500] + '...' if len(content) > 500 else content}</pre>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            display(HTML(reasoning_html))\n",
    "        elif msg_type == 'answer':\n",
    "            # Green for final answer\n",
    "            answer_html = f\"\"\"\n",
    "            <div style='background-color: #e8f5e9; border-left: 4px solid #4caf50; padding: 10px; margin: 10px 0;'>\n",
    "                <strong style='color: #2e7d32;'>Final Answer:</strong>\n",
    "                <pre style='color: #1b5e20; white-space: pre-wrap; font-family: monospace;'>{content[:500] + '...' if len(content) > 500 else content}</pre>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            display(HTML(answer_html))\n",
    "    \n",
    "    # Get final state\n",
    "    final_state = initial_state\n",
    "    for change in state_changes:\n",
    "        final_state.update(change['updates'])\n",
    "    \n",
    "    display(HTML(\"<hr style='margin: 20px 0;'>\"))\n",
    "    display(Markdown(\"### Final State\"))\n",
    "    \n",
    "    final_state_info = []\n",
    "    for key, value in final_state.items():\n",
    "        if key == 'reasoning_steps':\n",
    "            final_state_info.append(f\"- **{key}**: {len(value)} steps\")\n",
    "        elif key == 'messages':\n",
    "            final_state_info.append(f\"- **{key}**: {len(value)} messages\")\n",
    "        elif key == 'history':\n",
    "            final_state_info.append(f\"- **{key}**: {len(value)} Q&A pairs\")\n",
    "        elif key == 'final_answer':\n",
    "            final_state_info.append(f\"- **{key}**: {len(value)} characters\" if value else f\"- **{key}**: None\")\n",
    "        else:\n",
    "            final_state_info.append(f\"- **{key}**: {value}\")\n",
    "    display(Markdown(\"\\n\".join(final_state_info)))\n",
    "    \n",
    "    display(HTML(\"<hr style='margin: 20px 0;'>\"))\n",
    "    \n",
    "    # Statistics with nice formatting\n",
    "    stats_html = f\"\"\"\n",
    "    <div style='background-color: #f3e5f5; border-left: 4px solid #9c27b0; padding: 15px; margin: 10px 0;'>\n",
    "        <h3 style='color: #6a1b9a; margin-top: 0;'>Statistics</h3>\n",
    "        <ul style='color: #4a148c;'>\n",
    "            <li><strong>Total State Transitions:</strong> {len(state_changes)}</li>\n",
    "            <li><strong>Reasoning Steps:</strong> {final_state.get('reasoning_count', 0)}</li>\n",
    "            <li><strong>Nodes Executed:</strong> {', '.join(set(c['node'] for c in state_changes))}</li>\n",
    "            <li><strong>Thread Completed:</strong> {'Yes' if final_state.get('final_answer') else 'No'}</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(stats_html))\n",
    "    \n",
    "    # Update history\n",
    "    chatbot.history = final_state.get(\"history\", chatbot.history)\n",
    "    \n",
    "    return final_state\n",
    "\n",
    "# Example: View the complete lifecycle of a reasoning thread\n",
    "result = view_thread_lifecycle(\"What are the key differences between TCP and UDP protocols?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
